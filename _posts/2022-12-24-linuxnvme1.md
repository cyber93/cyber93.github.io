---
title:  "nvme_core_init 함수 개요 및 분석"
excerpt: "Linux NVMe Driver 이야기 #1"

toc: true
toc_sticky: true

categories:
  - NVMe Storage Technology
tags:
  - Linux NVMe Driver
---

<br>

> Linux의 nvme 드라이버에 대한 자세한 설명: https://developer.aliyun.com/article/596648
> Linux 커널 4.5에서 NVMe 드라이버 소스 코드 분석: https://hyunyoung2.github.io/2016/09/19/NVMe_Driver_Source_Code/?spm=a2c6h.12873639.article-detail.10.3b3ebbebloUoev
> NVMe 드라이버 분석 - 키 BAR 공간: https://blog.csdn.net/memblaze_2011/article/details/52766905?spm=a2c6h.12873639.article-detail.11.3b3ebbebloUoev

> [Linux NVMe Driver 이야기] https://blog.csdn.net/zhuzongpeng/category_12008684.html?spm=1001.2014.3001.5482
>
> 1. Linux NVMe 드라이버 연구 노트 1: nvme_core_init 함수 개요 및 분석
> https://mp.weixin.qq.com/s?__biz=MzIwNTUxNDgwNg==&mid=2247484418&idx=1&sn=9db09928b922278318c42f5467e1d514&chksm=972ef55ba0597c4de08c03bb1238f7e3f5e26fdb8af53e9fb538683eac1e837ca1e752c24379&scene=21#wechat_redirect
>

# nvme_core_init() 함수 개요 및 분석

Linux NVMe 드라이버는 Linux 아키텍처에서 블록 계층 아래에 있으며 NVMe 장치와의 상호 작용을 담당합니다. ([2013 FMS](https://www.flashmemorysummit.com/English/Collaterals/Proceedings/2013/20130812_PreConfD_Busch.pdf))

![img](/assets/images/linuxnvme1-1.png)

현재 NVMe 드라이버는 아래 그림과 같이 NVMe over Fabric 관련 장치도 지원합니다. ([2016 SDC](https://events.static.linuxfound.org/sites/events/files/slides/nvme-over-fabrics.pdf)). 여기에서 우리는 주로 **PCIe를 통한 NVMe**에 초점을 맞춥니다.

![img](/assets/images/linuxnvme1-2.png)



Linux 4.10.6에 포함된 NVMe 드라이버의 디렉토리는(linux-4.10.6\drivers\nvme) 두 개의 하위 폴더(host 및 target)와 두 개의 파일(Kconfig 및 Makefile)이 포함되어 있습니다. 

드라이버를 분석할 때 드라이버와 관련된 kconfig 및 Makefile 파일을 먼저 살펴보는 것이 가장 좋습니다. 파일 구조를 이해하고 관련 소스 코드를 읽어 보시기 바랍니다.

> Kconfig 파일의 역할은 다음과 같습니다.
>
> 1. make menuconfig 실행시 나타나는 구성 옵션입니다.
>
> 2. 사용자 구성 인터페이스 선택에 따라 구성 결과를 .config 구성 파일에 저장합니다(이 파일은 컴파일할 커널 구성 요소 및 컴파일 방법을 결정하기 위해 Makefile에서 이용됨).

먼저 nvme/host/kconfig의 내용을 살펴봅시다. nvme/target 디렉토리를 포함하여 NVMeOF 관련 내용은 생략합니다.

```makefile
config NVME_CORE
	tristate

config BLK_DEV_NVME
	tristate "NVM Express block device"
	depends on PCI && BLOCK
	select NVME_CORE

config BLK_DEV_NVME_SCSI
	bool "SCSI emulation for NVMe device nodes"
	depends on NVME_CORE
```

다음으로 **NVME_CORE, BLK_DEV_NVME, BLK_DEV_NVME_SCSI**와 관련된 nvme/host/Makefile의 내용을 확인합니다.

```makefile
obj-$(CONFIG_NVME_CORE)			+= nvme-core.o
obj-$(CONFIG_BLK_DEV_NVME)		+= nvme.o

nvme-core-y				:= core.o
nvme-core-$(CONFIG_BLK_DEV_NVME_SCSI)	+= scsi.o

nvme-y					+= pci.o
```

Kconfig 및 Makefile 분석을 통해 **NVMe over PCIe**와 관련된 core.c, pci.c, scsi.c 세 파일을 살펴 봅니다.



## nvme_core_init() 함수

core.c 파일에서 module_init(**nvme_core_init**)을 찾습니다. 바로 위에 위치한 nvme_core_init는 주로 두 가지 작업을 수행합니다.

1. *__register_chrdev* 함수를 호출하여 "nvme"라는 캐릭터 디바이스를 등록합니다.
2. *class_create* 함수를 호출하여 장치의 논리 클래스를 동적으로 생성하고 일부 필드의 초기화를 완료한 다음 커널에 추가합니다. 생성된 논리 클래스는 /sys/class/에서 확인 가능합니다.

```c
int __init nvme_core_init(void)
{
	int result;
    
    //1. 캐릭터 디바이스 "nvme" 등록
	result = __register_chrdev(nvme_char_major, 0, NVME_MINORS, "nvme", &nvme_dev_fops);
	if (result < 0)
		return result;
	else if (result > 0)
		nvme_char_major = result;

    //2. 새로운 nvme 클래스 생성, 소유자(Owner)는 THIS_MODULE
	nvme_class = class_create(THIS_MODULE, "nvme");
    //에러 발생시 캐릭터 디바이스 nvme 삭제
	if (IS_ERR(nvme_class)) {
		result = PTR_ERR(nvme_class);
		goto unregister_chrdev;
	}

	return 0;

 unregister_chrdev:
	__unregister_chrdev(nvme_char_major, 0, NVME_MINORS, "nvme");
	return result;
}

MODULE_LICENSE("GPL");
MODULE_VERSION("1.0");
module_init(nvme_core_init);
module_exit(nvme_core_exit);
```

> ◈ 캐릭터 디바이스를 등록 시, 장치 번호 관련 지식
>
> 
>
> 캐릭터 디바이스 또는 블록 디바이스에는 주 장치 번호(Major)와 보조 장치 번호(Minor)가 있습니다. 주 장치 번호는 특정 드라이버를 식별하는데 사용되고 보조 번호는 해당 드라이버를 사용하는 개별 장치를 식별하는데 사용됩니다. 예를 들어 Linux 시스템에 두 개의 NVMe SSD가 있는 경우, 주 장치 번호에 자동으로 번호(예: 8)가 할당되고 보조 장치 번호는 각각 1과 2가 됩니다.
>
> 예를 들어, 32비트 머신에서 장치 번호는 총 32비트이며 상위 12비트는 주 장치 번호를 나타내고 하위 20비트는 보조 장치 번호를 나타냅니다.
>
> | 주요 장비 번호 12자리 | 부장치번호 20자리 |
> | --------------------- | ----------------- |



## nvme_dev_fops 구조체

위에서 등록한 캐릭터 디바이스로 open, ioctl, release 인터페이스를 동작시킬 수 있습니다. nvme 캐릭터 디바이스의 파일 연산 구조  **nvme_dev_fops**는 다음과 같이 정의됩니다.

```c
static const struct file_operations nvme_dev_fops = {
	.owner		= THIS_MODULE,

    // open()은 장치를 여는데 사용되며 이 함수에서 장치를 초기화할 수 있습니다.
	.open		= nvme_dev_open, 

    // release()는 open() 함수에서 요청한 리소스를 해제하는 데 사용됩니다.
	.release	= nvme_dev_release,

    // nvme_dev_ioctl()은 장치별 명령을 실행하는 방법을 제공합니다.
	.unlocked_ioctl	= nvme_dev_ioctl,
    
	.compat_ioctl	= nvme_dev_ioctl,
    /* 2개의 unlocked_ioctl과 compat_ioctl이 있는데, 이 2개가 동시에 존재할 경우 unlocked_ioctl이 먼저 호출되고,
       compat_ioctl의 경우 CONFIG_COMPAT가 선언된 경우에만 호출됩니다.
       obj-$(CONFIG_COMPAT) += compat.o compat_ioctl.o */
};
```



### nvme_dev_open() 함수

모든 nvme 장치는 nvme_ctrl_list에 추가됩니다. 여기서 list_for_each_entry를 호출하여 nvme_ctrl_list를 탐색하여 인스턴스 하위 장치 번호에 해당하는 nvme 장치를 찾습니다. 그런 다음 ctrl->admin_q 및 ctrl->kref가 null인지 확인합니다. **최종적으로 찾은 nvme 디바이스는 file->private_data 영역에 위치합니다.**

```c
static int nvme_dev_open(struct inode *inode, struct file *file)
{
	struct nvme_ctrl *ctrl;
	int instance = iminor(inode); 	// Incode에서 부 장치 번호를 가져옵니다.
	int ret = -ENODEV;  			// 기본적으로 아직 특정 장치에 할당되지 않았습니다.

    // spin lock은 두 가지 옵션이 있습니다.
    // 끝날 때까지 기다리거나, 현재 프로세스를 일시 중단하고 다른 프로세스가 실행되도록 예약하는 것입니다.
	spin_lock(&dev_list_lock); 
    
	list_for_each_entry(ctrl, &nvme_ctrl_list, node) {
		if (ctrl->instance != instance)
			continue;
		if (!ctrl->admin_q) {
			ret = -EWOULDBLOCK;
			break;
		}

        if (!kref_get_unless_zero(&ctrl->kref))
			break;

		file->private_data = ctrl;
		ret = 0;
		break;
	}

	spin_unlock(&dev_list_lock);	//잠금 해제

	return ret;
}
```



### nvme_dev_release() 함수

nvme_dev_release는 상대적으로 간단하며 open() 함수에서 요청된 리소스를 해제하는데 사용됩니다.

```c
static int nvme_dev_release(struct inode *inode, struct file *file)
{
	nvme_put_ctrl(file->private_data);

	return 0;
}
```



### nvme_dev_ioctl() 함수

코드에서 총 5개의 명령이 nvme_dev_ioctl에 구현되어 있음을 알 수 있습니다. **NVME_IOCTL_ADMIN_CMD** 및 **NVME_IOCTL_IO_CMD**는 NVMe Spec에서 정의한 Admin 및 I/O CMD입니다. 구체적인 정의는 [NVMe 이야기 #2: Queue Management](/_posts/2022-11-21-nvme2.md)를 참조하십시오. 한 가지 주의할 점은 NVME_IOCTL_IO_CMD는 네임스페이스가 여러 개인 NVMe 장치를 지원하지 않는다는 것입니다.

```c
static long nvme_dev_ioctl(struct file *file, unsigned int cmd,
		unsigned long arg)
{
	struct nvme_ctrl *ctrl = file->private_data;
	void __user *argp = (void __user *)arg;

	switch (cmd) {
	case NVME_IOCTL_ADMIN_CMD:
		return nvme_user_cmd(ctrl, NULL, argp);

	case NVME_IOCTL_IO_CMD:
		return nvme_dev_user_cmd(ctrl, argp);

	case NVME_IOCTL_RESET:
		dev_warn(ctrl->device, "resetting controller\n");
		return ctrl->ops->reset_ctrl(ctrl);

	case NVME_IOCTL_SUBSYS_RESET:
		return nvme_reset_subsystem(ctrl);

	case NVME_IOCTL_RESCAN:
		nvme_queue_scan(ctrl);
		return 0;

	default:
		return -ENOTTY; //잘못된 ioctrl 명령
	}
}
```

NVME_IOCTL_RESET 및 NVME_IOCTL_SUBSYS_RESET 명령은 **nvme_ctrl_ops**를 통해 레지스터에 직접 접근합니다. 전자는 reset_ctrl을 호출하고 후자는 reg_write32를 호출합니다.

```c
static inline int nvme_reset_subsystem(struct nvme_ctrl *ctrl)
{
	if (!ctrl->subsystem)
		return -ENOTTY;

	return ctrl->ops->reg_write32(ctrl, NVME_REG_NSSR, 0x4E564D65);
}
```



## nvme_pci_ctrl_ops 구조체

**nvme_ctrl_ops**는 nvme 초기화에서 nvme_probe()를 호출할 때 **nvme_pci_ctrl_ops** 값이 할당됩니다 .

**nvme_pci_ctrl_ops**  구조체의(pci.c) 정의는 다음과 같습니다. 

```c
static const struct nvme_ctrl_ops nvme_pci_ctrl_ops = {
	.name				= "pcie",
	.module				= THIS_MODULE,
	.reg_read32			= nvme_pci_reg_read32,
	.reg_write32		= nvme_pci_reg_write32,
	.reg_read64			= nvme_pci_reg_read64,
	.reset_ctrl			= nvme_pci_reset_ctrl,
	.free_ctrl			= nvme_pci_free_ctrl,
	.submit_async_event	= nvme_pci_submit_async_event,
};
```

결국, NVME_IOCTL_RESET은 nvme_pci_reset_ctrl() 함수를 호출하고 NVME_IOCTL_SUBSYS_RESET는 nvme_pci_reg_write32() 함수를 호출한다는 것을 알 수 있습니다.



### nvme_pci_reset_ctrl() 함수

to_nvme_dev() 함수를 호출하여 nvme_ctrl의 주소를 얻어 nvme_dev에 할당한 후, nvme_reset() 함수를 호출하여 reset을 수행함을 알 수 있다.

```c
static int nvme_pci_reset_ctrl(struct nvme_ctrl *ctrl)
{
	struct nvme_dev *dev = to_nvme_dev(ctrl);
	int ret = nvme_reset(dev);

	if (!ret)
		flush_work(&dev->reset_work);

	return ret;
}
```



### nvme_reset() 함수

한 단계 더 나아가 **nvme_reset** 정의를 살펴보십시오.

```c
static int nvme_reset(struct nvme_dev *dev)
{
	if (!dev->ctrl.admin_q || blk_queue_dying(dev->ctrl.admin_q))
		return -ENODEV;

	if (work_busy(&dev->reset_work))
		return -ENODEV;

	if (!queue_work(nvme_workq, &dev->reset_work))
		return -EBUSY;

	return 0;
}
```

현재 작업이 바쁘면 초기화 실패, 즉, nvme 컨트롤러는 재설정 중에 유휴 상태여야 합니다.

유휴 상태인 경우 dev->reset_work를 호출하여 nvme 컨트롤러를 리셋합니다.

reset_work는 nvme 초기화에서 nvme_probe() 호출 시에도 할당되며, 할당 결과는 "nvme_reset_work"입니다.

이함수는 비교적 길기 때문에 여기서는 확장하지 않겠습니다~



### nvme_pci_reg_write32() 함수

***돌아가서 reset Ioctrl_subsys에 의해 호출되는 nvme_pci_reg_write32\*** 함수 가 어떻게 정의되는지 살펴보겠습니다 .

```c
static int nvme_pci_reg_write32(struct nvme_ctrl *ctrl, u32 off, u32 val)
{
	writel(val, to_nvme_dev(ctrl)->bar + off);

	return 0;
}
```



**nvme_reset_subsystem** 의 정의 와 결합하여 (다음과 같이) Ioctrl_subsys의 재설정은 막대 레지스터에 0x4E564D65를 직접 쓰는 것임을 발견했습니다.

```c
static inline int nvme_reset_subsystem(struct nvme_ctrl *ctrl)
{

	if (!ctrl->subsystem)
		return -ENOTTY;

	return ctrl->ops->reg_write32(ctrl, NVME_REG_NSSR, 0x4E564D65);
}
```



